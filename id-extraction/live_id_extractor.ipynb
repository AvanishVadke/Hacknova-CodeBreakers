{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfec54a0",
   "metadata": {},
   "source": [
    "# üé• Live ID Card Extraction - Trained Detection\n",
    "\n",
    "This notebook uses your existing ID card dataset to **train** the detection system, making it much more accurate for live capture.\n",
    "\n",
    "## Workflow:\n",
    "1. **Train on your dataset** - Learn what your ID cards look like\n",
    "2. **Live detection** - Use trained model for real-time capture\n",
    "3. **Extract information** - Name, Department, Moodle ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3dd53",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93dd991e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available: True\n",
      "Initializing EasyOCR...\n",
      "‚úÖ Ready!\n",
      "‚úÖ Ready!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from glob import glob\n",
    "\n",
    "# Check GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print(f\"GPU Available: {use_gpu}\")\n",
    "\n",
    "# Initialize EasyOCR\n",
    "print(\"Initializing EasyOCR...\")\n",
    "reader = easyocr.Reader(['en'], gpu=use_gpu, verbose=False)\n",
    "print(\"‚úÖ Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f05108",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f118eb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration loaded!\n",
      "üìÅ Data directory: data\n",
      "üìÅ Output directory: output\\live_capture\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "DATA_DIR = Path(\"data\")\n",
    "OUTPUT_DIR = Path(\"output/live_capture\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PHOTO_DIR = OUTPUT_DIR / \"photos\"\n",
    "PHOTO_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Camera settings\n",
    "CAMERA_INDEX = 0\n",
    "FRAME_WIDTH = 1280\n",
    "FRAME_HEIGHT = 720\n",
    "\n",
    "# Region definitions\n",
    "REGIONS = {\n",
    "    'ignore_top': (0, 0, 1, 0.24),\n",
    "    'photo': (0.20, 0.25, 0.55, 0.65),\n",
    "    'name': (0.10, 0.68, 0.90, 0.76),\n",
    "    'department': (0.10, 0.76, 0.90, 0.84),\n",
    "    'moodle_id': (0.10, 0.92, 0.70, 1.0),\n",
    "}\n",
    "\n",
    "# Department mapping\n",
    "DEPARTMENT_MAPPING = {\n",
    "    'COMP': 'Computer Engineering', 'COMPUTER': 'Computer Engineering',\n",
    "    'IT': 'Information Technology', 'INFORMATION TECHNOLOGY': 'Information Technology',\n",
    "    'AIML': 'AI & Machine Learning', 'AI ML': 'AI & Machine Learning',\n",
    "    'DS': 'Data Science', 'DATA SCIENCE': 'Data Science',\n",
    "    'EXTC': 'Electronics & Telecom', 'ELECTRONICS': 'Electronics & Telecom',\n",
    "    'MECH': 'Mechanical', 'MECHANICAL': 'Mechanical',\n",
    "}\n",
    "\n",
    "# Forbidden words for names\n",
    "NAME_FORBIDDEN_WORDS = [\n",
    "    'principal', 'dr', 'prof', 'college', 'institute', 'technology',\n",
    "    'computer', 'information', 'engineering', 'mechanical', 'electronics',\n",
    "    'aiml', 'data', 'science', 'id', 'no', 'moodle', 'student', 'card'\n",
    "]\n",
    "\n",
    "ENGINEERING_KEYWORDS = [\n",
    "    'computer', 'information', 'technology', 'engineering',\n",
    "    'mechanical', 'electronics', 'aiml', 'data', 'science'\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Configuration loaded!\")\n",
    "print(f\"üìÅ Data directory: {DATA_DIR}\")\n",
    "print(f\"üìÅ Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0989cf67",
   "metadata": {},
   "source": [
    "## Step 1: Train ID Card Detector on Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b82ed8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîç ANALYZING YOUR ID CARD DATASET\n",
      "======================================================================\n",
      "\n",
      "üìä Found 0 images in dataset\n",
      "\n",
      "Analyzing each image...\n",
      "\n",
      "üìê ID Card Statistics:\n",
      "   Average aspect ratio: 1.50\n",
      "   Std deviation: 0.20\n",
      "   Expected range: 1.10 to 1.90\n",
      "\n",
      "‚úÖ Training complete! Detector is ready.\n"
     ]
    }
   ],
   "source": [
    "def analyze_dataset_for_id_cards():\n",
    "    \"\"\"\n",
    "    Analyze your dataset to learn what ID cards look like\n",
    "    Returns: Statistics and reference features for detection\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîç ANALYZING YOUR ID CARD DATASET\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    image_files = list(DATA_DIR.glob(\"*.jpg\"))\n",
    "    print(f\"\\nüìä Found {len(image_files)} images in dataset\\n\")\n",
    "    \n",
    "    # Statistics\n",
    "    aspect_ratios = []\n",
    "    card_colors = []\n",
    "    card_features = []\n",
    "    \n",
    "    print(\"Analyzing each image...\")\n",
    "    for i, img_path in enumerate(image_files[:10], 1):  # Sample first 10\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            continue\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "        aspect_ratios.append(aspect_ratio)\n",
    "        \n",
    "        # Dominant color\n",
    "        avg_color = np.mean(img, axis=(0, 1))\n",
    "        card_colors.append(avg_color)\n",
    "        \n",
    "        print(f\"  {i}. {img_path.name[:30]:30} - {w}x{h} (ratio: {aspect_ratio:.2f})\")\n",
    "    \n",
    "    # Calculate statistics\n",
    "    avg_ratio = np.mean(aspect_ratios) if aspect_ratios else 1.5\n",
    "    std_ratio = np.std(aspect_ratios) if aspect_ratios else 0.2\n",
    "    \n",
    "    print(f\"\\nüìê ID Card Statistics:\")\n",
    "    print(f\"   Average aspect ratio: {avg_ratio:.2f}\")\n",
    "    print(f\"   Std deviation: {std_ratio:.2f}\")\n",
    "    print(f\"   Expected range: {avg_ratio - 2*std_ratio:.2f} to {avg_ratio + 2*std_ratio:.2f}\")\n",
    "    \n",
    "    return {\n",
    "        'avg_ratio': avg_ratio,\n",
    "        'std_ratio': std_ratio,\n",
    "        'min_ratio': avg_ratio - 2*std_ratio,\n",
    "        'max_ratio': avg_ratio + 2*std_ratio,\n",
    "        'sample_count': len(aspect_ratios)\n",
    "    }\n",
    "\n",
    "# Train the detector\n",
    "card_stats = analyze_dataset_for_id_cards()\n",
    "print(\"\\n‚úÖ Training complete! Detector is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5638082a",
   "metadata": {},
   "source": [
    "## Step 2: Trained Detection Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e9f61d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Ultra-lenient grayscale detection function loaded!\n",
      "Features:\n",
      "  - Grayscale conversion with CLAHE\n",
      "  - Very low thresholds (3-90% size, 0.45-0.95 AR)\n",
      "  - Intensity-based filtering\n",
      "  - Score threshold: 0.20\n"
     ]
    }
   ],
   "source": [
    "def detect_id_card_trained(frame, card_stats):\n",
    "    \"\"\"\n",
    "    ULTRA-LENIENT GRAYSCALE ID CARD DETECTION\n",
    "    Converts to grayscale for better edge detection and contrast\n",
    "    \"\"\"\n",
    "    \n",
    "    # === CONVERT TO GRAYSCALE FIRST ===\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply CLAHE for better contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    gray = clahe.apply(gray)\n",
    "    \n",
    "    # === STEP 1: Enhanced edge detection ===\n",
    "    bilateral = cv2.bilateralFilter(gray, 11, 80, 80)\n",
    "    \n",
    "    # Multiple Canny thresholds - VERY LENIENT\n",
    "    edges1 = cv2.Canny(bilateral, 30, 100)\n",
    "    edges2 = cv2.Canny(bilateral, 50, 150)\n",
    "    edges3 = cv2.Canny(gray, 40, 120)\n",
    "    \n",
    "    # Combine edges\n",
    "    edges_combined = cv2.bitwise_or(edges1, edges2)\n",
    "    edges_combined = cv2.bitwise_or(edges_combined, edges3)\n",
    "    \n",
    "    # Morphological closing - STRONG\n",
    "    kernel_ellipse = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (9, 9))\n",
    "    kernel_rect = cv2.getStructuringElement(cv2.MORPH_RECT, (7, 7))\n",
    "    \n",
    "    edges_closed = cv2.morphologyEx(edges_combined, cv2.MORPH_CLOSE, kernel_ellipse, iterations=5)\n",
    "    edges_dilated = cv2.dilate(edges_closed, kernel_rect, iterations=3)\n",
    "    \n",
    "    # === STEP 2: Find contours ===\n",
    "    contours, _ = cv2.findContours(edges_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if not contours:\n",
    "        return None\n",
    "    \n",
    "    frame_h, frame_w = frame.shape[:2]\n",
    "    frame_area = frame_h * frame_w\n",
    "    \n",
    "    candidates = []\n",
    "    \n",
    "    for contour in sorted(contours, key=cv2.contourArea, reverse=True)[:20]:\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        # === VERY LENIENT SIZE FILTER ===\n",
    "        if area < 0.03 * frame_area or area > 0.90 * frame_area:\n",
    "            continue\n",
    "        \n",
    "        # Approximate to polygon\n",
    "        peri = cv2.arcLength(contour, True)\n",
    "        approx = cv2.approxPolyDP(contour, 0.02 * peri, True)\n",
    "        \n",
    "        if len(approx) < 4:\n",
    "            continue\n",
    "        \n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # === VERY LENIENT SIZE CHECK ===\n",
    "        if w < 80 or h < 120:\n",
    "            continue\n",
    "        \n",
    "        # === VERY LENIENT ASPECT RATIO - PORTRAIT ===\n",
    "        aspect_ratio = w / h\n",
    "        if aspect_ratio < 0.45 or aspect_ratio > 0.95:\n",
    "            continue\n",
    "        \n",
    "        # === VERY LENIENT RECTANGULARITY ===\n",
    "        rect_area = w * h\n",
    "        rectangularity = area / rect_area if rect_area > 0 else 0\n",
    "        if rectangularity < 0.60:\n",
    "            continue\n",
    "        \n",
    "        # === ANALYZE GRAYSCALE VALUES ===\n",
    "        card_roi = gray[y:y+h, x:x+w]\n",
    "        \n",
    "        # Check for mixed intensity values (white + darker sections)\n",
    "        mean_intensity = np.mean(card_roi)\n",
    "        std_intensity = np.std(card_roi)\n",
    "        \n",
    "        # Cards should have good contrast (varying intensities)\n",
    "        if std_intensity < 20:  # Too uniform\n",
    "            continue\n",
    "        \n",
    "        # === EDGE DENSITY CHECK ===\n",
    "        edge_roi = edges_combined[y:y+h, x:x+w]\n",
    "        edge_density = np.count_nonzero(edge_roi) / (w * h)\n",
    "        \n",
    "        # Should have some edges (text/photo) but not too many\n",
    "        if edge_density < 0.02 or edge_density > 0.20:\n",
    "            continue\n",
    "        \n",
    "        # === CALCULATE SCORE ===\n",
    "        score = 0.0\n",
    "        \n",
    "        # Size score\n",
    "        ideal_area_ratio = 0.25\n",
    "        area_ratio = area / frame_area\n",
    "        size_score = 1.0 - abs(area_ratio - ideal_area_ratio) / ideal_area_ratio\n",
    "        size_score = max(0, size_score)\n",
    "        score += size_score * 0.25\n",
    "        \n",
    "        # Aspect ratio score (ideal: 0.63)\n",
    "        ideal_ar = 0.63\n",
    "        ar_score = 1.0 - abs(aspect_ratio - ideal_ar) / ideal_ar\n",
    "        ar_score = max(0, ar_score)\n",
    "        score += ar_score * 0.20\n",
    "        \n",
    "        # Rectangularity score\n",
    "        score += rectangularity * 0.20\n",
    "        \n",
    "        # Contrast score (higher std = better)\n",
    "        contrast_score = min(1.0, std_intensity / 100.0)\n",
    "        score += contrast_score * 0.20\n",
    "        \n",
    "        # Edge density score\n",
    "        ideal_edge = 0.08\n",
    "        edge_score = 1.0 - abs(edge_density - ideal_edge) / ideal_edge\n",
    "        edge_score = max(0, edge_score)\n",
    "        score += edge_score * 0.15\n",
    "        \n",
    "        candidates.append({\n",
    "            'bbox': (x, y, w, h),\n",
    "            'score': score,\n",
    "            'aspect_ratio': aspect_ratio,\n",
    "            'rectangularity': rectangularity,\n",
    "            'area_ratio': area_ratio,\n",
    "            'mean_intensity': mean_intensity,\n",
    "            'std_intensity': std_intensity,\n",
    "            'edge_density': edge_density\n",
    "        })\n",
    "    \n",
    "    # === STEP 3: Select best candidate ===\n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # VERY LOW THRESHOLD\n",
    "    candidates = [c for c in candidates if c['score'] >= 0.20]\n",
    "    \n",
    "    if not candidates:\n",
    "        return None\n",
    "    \n",
    "    # Sort by score\n",
    "    best = max(candidates, key=lambda x: x['score'])\n",
    "    \n",
    "    print(f\"‚úì Card detected! Score: {best['score']:.3f}, AR: {best['aspect_ratio']:.2f}, \"\n",
    "          f\"Intensity: {best['mean_intensity']:.1f}¬±{best['std_intensity']:.1f}, \"\n",
    "          f\"Edges: {best['edge_density']:.3f}\")\n",
    "    \n",
    "    return best['bbox']\n",
    "\n",
    "\n",
    "print(\"‚úì Ultra-lenient grayscale detection function loaded!\")\n",
    "print(\"Features:\")\n",
    "print(\"  - Grayscale conversion with CLAHE\")\n",
    "print(\"  - Very low thresholds (3-90% size, 0.45-0.95 AR)\")\n",
    "print(\"  - Intensity-based filtering\")\n",
    "print(\"  - Score threshold: 0.20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fb987e",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9b2f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def get_region(img, region_coords):\n",
    "    h, w = img.shape[:2]\n",
    "    x1, y1, x2, y2 = region_coords\n",
    "    x1_px = max(0, int(x1 * w))\n",
    "    y1_px = max(0, int(y1 * h))\n",
    "    x2_px = min(w, int(x2 * w))\n",
    "    y2_px = min(h, int(y2 * h))\n",
    "    return img[y1_px:y2_px, x1_px:x2_px], (x1_px, y1_px, x2_px, y2_px)\n",
    "\n",
    "def extract_text(img_region):\n",
    "    try:\n",
    "        if img_region.size == 0:\n",
    "            return ''\n",
    "        results = reader.readtext(img_region, detail=0, paragraph=False)\n",
    "        return ' '.join(results).strip() if results else ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def clean_name(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    text_clean = re.sub(r'\\d+', '', text)\n",
    "    text_clean = re.sub(r'[^a-zA-Z\\s]', '', text_clean)\n",
    "    words = [w.title() for w in text_clean.split() if len(w) >= 2 and \n",
    "             w.lower() not in NAME_FORBIDDEN_WORDS and\n",
    "             not any(kw in w.lower() for kw in ENGINEERING_KEYWORDS)]\n",
    "    return ' '.join(words) if 2 <= len(words) <= 4 else ''\n",
    "\n",
    "def normalize_department(text):\n",
    "    if not text:\n",
    "        return ''\n",
    "    text_upper = text.upper().strip()\n",
    "    text_upper = re.sub(r'\\d+', '', text_upper)\n",
    "    text_upper = text_upper.replace('ID NO', '').replace('ID', '').replace('NO', '')\n",
    "    text_upper = re.sub(r'[^A-Z\\s&]', '', text_upper).strip()\n",
    "    \n",
    "    for key, value in DEPARTMENT_MAPPING.items():\n",
    "        if key in text_upper:\n",
    "            return value\n",
    "    \n",
    "    if any(kw in text_upper.lower() for kw in ENGINEERING_KEYWORDS):\n",
    "        return text_upper.title()\n",
    "    return ''\n",
    "\n",
    "def extract_moodle_id(text):\n",
    "    text = text.replace('ID NO', '').replace('ID', '').replace('NO', '')\n",
    "    match = re.search(r'2\\d{7}', text)\n",
    "    return match.group(0) if match else None\n",
    "\n",
    "print(\"‚úÖ Helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedea495",
   "metadata": {},
   "source": [
    "## Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ff2b8f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Extraction functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def extract_from_id_card(card_img):\n",
    "    \"\"\"Extract all information from ID card\"\"\"\n",
    "    name_region, name_coords = get_region(card_img, REGIONS['name'])\n",
    "    name_text = extract_text(name_region)\n",
    "    name = clean_name(name_text)\n",
    "    \n",
    "    dept_region, dept_coords = get_region(card_img, REGIONS['department'])\n",
    "    dept_text = extract_text(dept_region)\n",
    "    department = normalize_department(dept_text)\n",
    "    \n",
    "    id_region, id_coords = get_region(card_img, REGIONS['moodle_id'])\n",
    "    id_text = extract_text(id_region)\n",
    "    moodle_id = extract_moodle_id(id_text)\n",
    "    \n",
    "    photo_region, photo_coords = get_region(card_img, REGIONS['photo'])\n",
    "    \n",
    "    return {\n",
    "        'name': name, 'name_text': name_text, 'name_coords': name_coords,\n",
    "        'department': department, 'dept_text': dept_text, 'dept_coords': dept_coords,\n",
    "        'moodle_id': moodle_id, 'id_text': id_text, 'id_coords': id_coords,\n",
    "        'photo': photo_region, 'photo_coords': photo_coords\n",
    "    }\n",
    "\n",
    "def draw_overlay(frame, card_bbox, info):\n",
    "    \"\"\"Draw complete overlay with regions and info\"\"\"\n",
    "    overlay = frame.copy()\n",
    "    \n",
    "    # Draw card box\n",
    "    if card_bbox:\n",
    "        x, y, w, h = card_bbox\n",
    "        cv2.rectangle(overlay, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        cv2.putText(overlay, \"ID CARD\", (x, y-10),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw regions on card\n",
    "        if info:\n",
    "            colors = {'photo': (0,255,0), 'name': (0,0,255), \n",
    "                     'dept': (255,0,0), 'id': (0,255,255)}\n",
    "            \n",
    "            for region_name, color in colors.items():\n",
    "                coords_key = f\"{region_name}_coords\" if region_name != 'id' else 'id_coords'\n",
    "                if coords_key in info:\n",
    "                    rx1, ry1, rx2, ry2 = info[coords_key]\n",
    "                    cv2.rectangle(overlay, (x+rx1, y+ry1), (x+rx2, y+ry2), color, 2)\n",
    "                    cv2.putText(overlay, region_name.upper()[:4], (x+rx1, y+ry1-5),\n",
    "                               cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)\n",
    "    \n",
    "    # Info panel\n",
    "    cv2.rectangle(overlay, (10, 10), (600, 200), (0, 0, 0), -1)\n",
    "    cv2.rectangle(overlay, (10, 10), (600, 200), (0, 255, 0), 2)\n",
    "    cv2.putText(overlay, \"LIVE ID CAPTURE\", (20, 40),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "    \n",
    "    y_pos = 75\n",
    "    if info:\n",
    "        for field, label in [('name', 'Name'), ('department', 'Dept'), ('moodle_id', 'ID')]:\n",
    "            value = info.get(field, '')\n",
    "            status = \"‚úì\" if value else \"‚úó\"\n",
    "            color = (0, 255, 0) if value else (0, 0, 255)\n",
    "            cv2.putText(overlay, f\"{status} {label}: {value if value else 'Not detected'}\",\n",
    "                       (20, y_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "            y_pos += 35\n",
    "    else:\n",
    "        cv2.putText(overlay, \"Hold ID card in frame...\", (20, y_pos),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)\n",
    "    \n",
    "    # Controls\n",
    "    y_pos = frame.shape[0] - 50\n",
    "    cv2.rectangle(overlay, (10, y_pos-10), (650, frame.shape[0]-10), (0, 0, 0), -1)\n",
    "    cv2.putText(overlay, \"[SPACE] Capture | [Q] Quit | [S] Save | [D] Debug\",\n",
    "               (20, y_pos + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "    \n",
    "    return cv2.addWeighted(overlay, 0.85, frame, 0.15, 0)\n",
    "\n",
    "print(\"‚úÖ Extraction functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8210acbe",
   "metadata": {},
   "source": [
    "## üöÄ Live Capture System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0de87468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Live detection function loaded!\n",
      "Run: live_id_card_detection()\n"
     ]
    }
   ],
   "source": [
    "def live_id_card_detection():\n",
    "    \"\"\"ULTRA-FAST GRAYSCALE LIVE DETECTION - Press SPACE to capture\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"GRAYSCALE ID CARD LIVE DETECTION\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nControls:\")\n",
    "    print(\"  SPACE - Detect & process ID card\")\n",
    "    print(\"  Q     - Quit\")\n",
    "    print(\"\\nTips for best detection:\")\n",
    "    print(\"  - Hold card FLAT and CENTERED\")\n",
    "    print(\"  - Good lighting, no shadows\")\n",
    "    print(\"  - Card should fill 20-50% of frame\")\n",
    "    print(\"  - Portrait orientation (vertical)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Cannot open webcam!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n‚úì Webcam opened: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}\")\n",
    "    \n",
    "    last_detection = None\n",
    "    frame_count = 0\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_count += 1\n",
    "            display_frame = frame.copy()\n",
    "            \n",
    "            # Show grayscale preview in corner\n",
    "            gray_preview = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_preview = cv2.resize(gray_preview, (200, 150))\n",
    "            gray_preview_bgr = cv2.cvtColor(gray_preview, cv2.COLOR_GRAY2BGR)\n",
    "            display_frame[10:160, 10:210] = gray_preview_bgr\n",
    "            cv2.rectangle(display_frame, (10, 10), (210, 160), (0, 255, 0), 2)\n",
    "            cv2.putText(display_frame, \"GRAYSCALE\", (15, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            # Show last detection\n",
    "            if last_detection:\n",
    "                x, y, w, h = last_detection\n",
    "                cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "                cv2.putText(display_frame, \"LAST DETECTED\", (x, y-10),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Instructions\n",
    "            cv2.putText(display_frame, \"Press SPACE to detect ID card\", \n",
    "                       (20, frame.shape[0] - 20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('ID Card Detection (Grayscale)', display_frame)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                print(\"\\nüëã Exiting...\")\n",
    "                break\n",
    "            \n",
    "            elif key == ord(' '):\n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(f\"FRAME {frame_count} - PROCESSING...\")\n",
    "                print('='*70)\n",
    "                \n",
    "                import time\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Detect card\n",
    "                bbox = detect_id_card_trained(frame, card_stats)\n",
    "                \n",
    "                if bbox is None:\n",
    "                    print(\"‚ùå No ID card detected\")\n",
    "                    print(\"   Try:\")\n",
    "                    print(\"   - Better lighting\")\n",
    "                    print(\"   - Hold card flatter\")\n",
    "                    print(\"   - Center the card\")\n",
    "                    print(\"   - Make card fill 20-50% of frame\")\n",
    "                    continue\n",
    "                \n",
    "                last_detection = bbox\n",
    "                x, y, w, h = bbox\n",
    "                \n",
    "                print(f\"‚úÖ Card detected at: x={x}, y={y}, w={w}, h={h}\")\n",
    "                \n",
    "                # Crop card\n",
    "                card_img = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # Process with EasyOCR\n",
    "                print(\"\\nüìù Running OCR...\")\n",
    "                results = reader.readtext(card_img)\n",
    "                \n",
    "                # Extract fields\n",
    "                all_text = ' '.join([text for (_, text, _) in results])\n",
    "                print(f\"\\nüìÑ Extracted text: {all_text}\")\n",
    "                \n",
    "                # Try to identify name, dept, ID\n",
    "                name = \"\"\n",
    "                dept = \"\"\n",
    "                moodle_id = \"\"\n",
    "                \n",
    "                for (bbox_ocr, text, conf) in results:\n",
    "                    text_clean = text.strip().upper()\n",
    "                    \n",
    "                    # Department matching\n",
    "                    for key, dept_name in DEPARTMENT_MAPPING.items():\n",
    "                        if key in text_clean:\n",
    "                            dept = dept_name\n",
    "                            break\n",
    "                    \n",
    "                    # Moodle ID matching (8 digits starting with 2)\n",
    "                    import re\n",
    "                    id_match = re.search(r'2\\d{7}', text_clean)\n",
    "                    if id_match:\n",
    "                        moodle_id = id_match.group()\n",
    "                    \n",
    "                    # Name (heuristic: longest alphabetic string)\n",
    "                    if len(text.split()) >= 2 and text.isalpha() and len(text) > len(name):\n",
    "                        name = text\n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                \n",
    "                print(f\"\\n{'='*70}\")\n",
    "                print(\"RESULTS:\")\n",
    "                print(f\"  Name:       {name or 'Not found'}\")\n",
    "                print(f\"  Department: {dept or 'Not found'}\")\n",
    "                print(f\"  Moodle ID:  {moodle_id or 'Not found'}\")\n",
    "                print(f\"  Time:       {elapsed:.2f}s\")\n",
    "                print('='*70)\n",
    "                \n",
    "                # Show detected card\n",
    "                cv2.imshow('Detected Card', card_img)\n",
    "                cv2.waitKey(2000)\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\n‚úì Cleanup complete\")\n",
    "\n",
    "\n",
    "print(\"‚úì Live detection function loaded!\")\n",
    "print(\"Run: live_id_card_detection()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce674921",
   "metadata": {},
   "source": [
    "## ‚ñ∂Ô∏è RUN THIS - Start Live Capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a50f9647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üé• STARTING TRAINED LIVE CAPTURE\n",
      "======================================================================\n",
      "\n",
      "Controls: [SPACE] Capture | [Q] Quit | [S] Save | [D] Debug\n",
      "\n",
      "üé¨ Opening camera...\n",
      "\n",
      "‚úÖ Camera ready: 1280x720\n",
      "\n",
      "üí° Position your ID card horizontally in the frame\n",
      "   Wait for green box and all ‚úì marks before pressing SPACE\n",
      "   Press D for debug mode to see what's being detected\n",
      "\n",
      "‚úÖ Camera ready: 1280x720\n",
      "\n",
      "üí° Position your ID card horizontally in the frame\n",
      "   Wait for green box and all ‚úì marks before pressing SPACE\n",
      "   Press D for debug mode to see what's being detected\n",
      "\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "üîß Debug mode: ON\n",
      "   Yellow boxes = All large contours found\n",
      "   Green box = Detected ID card\n",
      "   Numbers show aspect ratio and size %\n",
      "\n",
      "\n",
      "üîß Debug mode: ON\n",
      "   Yellow boxes = All large contours found\n",
      "   Green box = Detected ID card\n",
      "   Numbers show aspect ratio and size %\n",
      "\n",
      "‚úì Card detected! Score: 0.567, AR: 0.88, Intensity: 162.0¬±54.1, Edges: 0.121\n",
      "‚úì Card detected! Score: 0.564, AR: 0.89, Intensity: 159.4¬±54.3, Edges: 0.123\n",
      "‚úì Card detected! Score: 0.564, AR: 0.89, Intensity: 159.4¬±54.3, Edges: 0.123\n",
      "‚úì Card detected! Score: 0.567, AR: 0.88, Intensity: 162.0¬±54.1, Edges: 0.121\n",
      "‚úì Card detected! Score: 0.564, AR: 0.89, Intensity: 159.4¬±54.3, Edges: 0.123\n",
      "‚úì Card detected! Score: 0.564, AR: 0.89, Intensity: 159.4¬±54.3, Edges: 0.123\n",
      "‚úì Card detected! Score: 0.838, AR: 0.59, Intensity: 97.3¬±53.0, Edges: 0.081\n",
      "‚úì Card detected! Score: 0.838, AR: 0.59, Intensity: 97.3¬±53.0, Edges: 0.081\n",
      "‚úì Card detected! Score: 0.790, AR: 0.70, Intensity: 102.9¬±53.4, Edges: 0.075\n",
      "‚úì Card detected! Score: 0.790, AR: 0.70, Intensity: 102.9¬±53.4, Edges: 0.075\n",
      "‚úì Card detected! Score: 0.695, AR: 0.71, Intensity: 122.9¬±55.6, Edges: 0.117\n",
      "‚úì Card detected! Score: 0.682, AR: 0.71, Intensity: 123.7¬±54.5, Edges: 0.123\n",
      "‚úì Card detected! Score: 0.695, AR: 0.71, Intensity: 122.9¬±55.6, Edges: 0.117\n",
      "‚úì Card detected! Score: 0.682, AR: 0.71, Intensity: 123.7¬±54.5, Edges: 0.123\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "\n",
      "‚ö†Ô∏è  No card detected - try:\n",
      "   - Move card closer/farther\n",
      "   - Ensure card is flat and horizontal\n",
      "   - Press D to see debug view\n",
      "‚úì Card detected! Score: 0.832, AR: 0.64, Intensity: 100.7¬±56.8, Edges: 0.084\n",
      "‚úì Card detected! Score: 0.832, AR: 0.64, Intensity: 100.7¬±56.8, Edges: 0.084\n",
      "‚úì Card detected! Score: 0.649, AR: 0.81, Intensity: 128.1¬±54.2, Edges: 0.098\n",
      "‚úì Card detected! Score: 0.649, AR: 0.81, Intensity: 128.1¬±54.2, Edges: 0.098\n",
      "‚úì Card detected! Score: 0.836, AR: 0.61, Intensity: 98.0¬±56.6, Edges: 0.076\n",
      "‚úì Card detected! Score: 0.836, AR: 0.61, Intensity: 98.0¬±56.6, Edges: 0.076\n",
      "‚úì Card detected! Score: 0.836, AR: 0.61, Intensity: 98.0¬±56.6, Edges: 0.076\n",
      "‚úì Card detected! Score: 0.836, AR: 0.61, Intensity: 98.0¬±56.6, Edges: 0.076\n",
      "\n",
      "======================================================================\n",
      "üìä SESSION COMPLETE - CAPTURED 0 IDs\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Done!\n",
      "\n",
      "======================================================================\n",
      "üìä SESSION COMPLETE - CAPTURED 0 IDs\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Done!\n"
     ]
    }
   ],
   "source": [
    "# Start the trained live capture system\n",
    "run_live_capture(card_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b900ff20",
   "metadata": {},
   "source": [
    "## üß™ Test Detection on Single Image (Optional)\n",
    "\n",
    "Run this to test detection on one of your dataset images before trying live capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d78632b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image not found: data\\abhishek.jpg\n"
     ]
    }
   ],
   "source": [
    "# Test detection on a sample image\n",
    "test_img_path = DATA_DIR / \"abhishek.jpg\"  # Change to any image name\n",
    "if test_img_path.exists():\n",
    "    test_img = cv2.imread(str(test_img_path))\n",
    "    \n",
    "    print(f\"Testing detection on: {test_img_path.name}\")\n",
    "    print(f\"Image size: {test_img.shape[1]}x{test_img.shape[0]}\")\n",
    "    \n",
    "    # Try detection\n",
    "    bbox = detect_id_card_trained(test_img, card_stats)\n",
    "    \n",
    "    if bbox:\n",
    "        x, y, w, h = bbox\n",
    "        ar = w/h if h > 0 else 0\n",
    "        print(f\"‚úÖ DETECTED! Box: ({x}, {y}, {w}, {h})\")\n",
    "        print(f\"   Aspect ratio: {ar:.2f}\")\n",
    "        print(f\"   Size: {w}x{h}\")\n",
    "        \n",
    "        # Draw on image\n",
    "        result = test_img.copy()\n",
    "        cv2.rectangle(result, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "        \n",
    "        # Show\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(f\"Detection Test - {test_img_path.name}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ùå NOT DETECTED - Card not found in image\")\n",
    "        print(\"   Try adjusting detection parameters or use debug mode\")\n",
    "else:\n",
    "    print(f\"Image not found: {test_img_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c20c0",
   "metadata": {},
   "source": [
    "## View Captured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56b0753e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "GRAYSCALE ID CARD LIVE DETECTION\n",
      "======================================================================\n",
      "\n",
      "Controls:\n",
      "  SPACE - Detect & process ID card\n",
      "  Q     - Quit\n",
      "\n",
      "Tips for best detection:\n",
      "  - Hold card FLAT and CENTERED\n",
      "  - Good lighting, no shadows\n",
      "  - Card should fill 20-50% of frame\n",
      "  - Portrait orientation (vertical)\n",
      "======================================================================\n",
      "\n",
      "‚úì Webcam opened: 1280x720\n",
      "\n",
      "‚úì Webcam opened: 1280x720\n",
      "\n",
      "üëã Exiting...\n",
      "\n",
      "üëã Exiting...\n",
      "\n",
      "‚úì Cleanup complete\n",
      "\n",
      "‚úì Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "# Run the ultra-lenient grayscale detection!\n",
    "live_id_card_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac12bc8d",
   "metadata": {},
   "source": [
    "# üîê Face Verification System\n",
    "\n",
    "**Complete ID Card Face Verification against Database**\n",
    "\n",
    "Features:\n",
    "- Webcam capture of ID card\n",
    "- Extract student photo from ID card (APSIT layout)\n",
    "- Generate face embeddings using DeepFace + Facenet\n",
    "- Match against database (students.csv)\n",
    "- Cosine similarity with threshold 0.6\n",
    "- Side-by-side visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fa4698ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "25-10-04 03:07:56 - Directory C:\\Users\\DELL\\.deepface has been created\n",
      "25-10-04 03:07:56 - Directory C:\\Users\\DELL\\.deepface\\weights has been created\n",
      "25-10-04 03:07:56 - Directory C:\\Users\\DELL\\.deepface has been created\n",
      "25-10-04 03:07:56 - Directory C:\\Users\\DELL\\.deepface\\weights has been created\n",
      "‚úÖ Face verification imports loaded!\n",
      "   Model: Facenet\n",
      "   Threshold: 0.6\n",
      "   Database: data\\students.csv\n",
      "   GPU Available: True\n",
      "‚úÖ Face verification imports loaded!\n",
      "   Model: Facenet\n",
      "   Threshold: 0.6\n",
      "   Database: data\\students.csv\n",
      "   GPU Available: True\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install deepface scikit-learn tf-keras -q\n",
    "\n",
    "# Import additional libraries for face verification\n",
    "from deepface import DeepFace\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "FACE_MODEL = 'Facenet'  # High accuracy, 512-d embeddings\n",
    "SIMILARITY_THRESHOLD = 0.6  # Cosine similarity threshold\n",
    "DB_FILE = DATA_DIR / \"students.csv\"\n",
    "SAMPLE_FACE = DATA_DIR / \"sample_face.jpg\"  # For testing\n",
    "CROPPED_OUTPUT = OUTPUT_DIR / \"cropped_photo.jpg\"\n",
    "\n",
    "# ID card photo crop coordinates (APSIT layout)\n",
    "ID_PHOTO_CROP = {\n",
    "    'x1': 0.25,  # 25% from left\n",
    "    'y1': 0.35,  # 35% from top\n",
    "    'x2': 0.55,  # 55% from left\n",
    "    'y2': 0.65   # 65% from top\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Face verification imports loaded!\")\n",
    "print(f\"   Model: {FACE_MODEL}\")\n",
    "print(f\"   Threshold: {SIMILARITY_THRESHOLD}\")\n",
    "print(f\"   Database: {DB_FILE}\")\n",
    "print(f\"   GPU Available: {use_gpu}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd2ce5",
   "metadata": {},
   "source": [
    "## Core Face Verification Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4f6c460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Face verification functions loaded!\n",
      "Functions:\n",
      "  - capture_id_card() ‚Üí captures from webcam\n",
      "  - extract_photo(img) ‚Üí crops student photo\n",
      "  - get_embedding(img) ‚Üí generates 512-d embedding\n",
      "  - match_embedding(query, db, df) ‚Üí finds best match\n"
     ]
    }
   ],
   "source": [
    "def capture_id_card():\n",
    "    \"\"\"\n",
    "    Capture ID card image from webcam\n",
    "    Returns: Grayscale denoised image frame or None\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üì∑ CAPTURING ID CARD FROM WEBCAM\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"Instructions:\")\n",
    "    print(\"  - Hold ID card flat and centered\")\n",
    "    print(\"  - Press SPACE to capture\")\n",
    "    print(\"  - Press Q to cancel\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    cap = cv2.VideoCapture(CAMERA_INDEX)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"‚ùå Cannot open webcam!\")\n",
    "        return None\n",
    "    \n",
    "    captured_frame = None\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Convert to grayscale for preview\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            gray_bgr = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "            \n",
    "            # Show both color and grayscale\n",
    "            display = frame.copy()\n",
    "            small_gray = cv2.resize(gray_bgr, (200, 150))\n",
    "            display[10:160, 10:210] = small_gray\n",
    "            cv2.rectangle(display, (10, 10), (210, 160), (0, 255, 0), 2)\n",
    "            cv2.putText(display, \"GRAYSCALE\", (15, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            \n",
    "            cv2.putText(display, \"Press SPACE to capture ID card\", \n",
    "                       (20, frame.shape[0] - 20),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Capture ID Card', display)\n",
    "            \n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            if key == ord('q'):\n",
    "                print(\"‚ùå Capture cancelled\")\n",
    "                break\n",
    "            elif key == ord(' '):\n",
    "                # Convert to grayscale\n",
    "                gray_captured = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                # Apply denoising (dust/noise reduction)\n",
    "                print(\"üßπ Applying image cleaning (denoising)...\")\n",
    "                denoised = cv2.fastNlMeansDenoising(\n",
    "                    gray_captured,\n",
    "                    h=10,  # Filter strength\n",
    "                    templateWindowSize=7,\n",
    "                    searchWindowSize=21\n",
    "                )\n",
    "                \n",
    "                # Save grayscale denoised image\n",
    "                output_path = OUTPUT_DIR / \"live_capture\" / \"id_card.jpg\"\n",
    "                cv2.imwrite(str(output_path), denoised)\n",
    "                print(f\"‚úÖ Grayscale denoised image saved to: {output_path}\")\n",
    "                \n",
    "                # Return as BGR for compatibility with extract_photo\n",
    "                captured_frame = cv2.cvtColor(denoised, cv2.COLOR_GRAY2BGR)\n",
    "                print(\"‚úÖ ID card captured!\")\n",
    "                break\n",
    "    \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"üßπ All windows closed\")\n",
    "    \n",
    "    return captured_frame\n",
    "\n",
    "\n",
    "def extract_photo(img):\n",
    "    \"\"\"\n",
    "    Extract student photo from ID card using APSIT layout\n",
    "    Args:\n",
    "        img: BGR image of ID card\n",
    "    Returns:\n",
    "        cropped photo (BGR) or None\n",
    "    \"\"\"\n",
    "    if img is None:\n",
    "        return None\n",
    "    \n",
    "    h, w = img.shape[:2]\n",
    "    \n",
    "    # Calculate crop coordinates\n",
    "    x1 = int(ID_PHOTO_CROP['x1'] * w)\n",
    "    y1 = int(ID_PHOTO_CROP['y1'] * h)\n",
    "    x2 = int(ID_PHOTO_CROP['x2'] * w)\n",
    "    y2 = int(ID_PHOTO_CROP['y2'] * h)\n",
    "    \n",
    "    # Ensure valid bounds\n",
    "    x1, y1 = max(0, x1), max(0, y1)\n",
    "    x2, y2 = min(w, x2), min(h, y2)\n",
    "    \n",
    "    if x2 <= x1 or y2 <= y1:\n",
    "        print(\"‚ùå Invalid crop coordinates\")\n",
    "        return None\n",
    "    \n",
    "    cropped = img[y1:y2, x1:x2]\n",
    "    \n",
    "    print(f\"‚úÖ Photo extracted: {cropped.shape[1]}x{cropped.shape[0]}\")\n",
    "    print(f\"   Crop region: ({x1}, {y1}) to ({x2}, {y2})\")\n",
    "    \n",
    "    # Save cropped photo\n",
    "    cv2.imwrite(str(CROPPED_OUTPUT), cropped)\n",
    "    print(f\"   Saved to: {CROPPED_OUTPUT}\")\n",
    "    \n",
    "    return cropped\n",
    "\n",
    "\n",
    "def get_embedding(img_path_or_array):\n",
    "    \"\"\"\n",
    "    Generate face embedding using DeepFace + Facenet\n",
    "    Args:\n",
    "        img_path_or_array: Path to image or numpy array (BGR)\n",
    "    Returns:\n",
    "        numpy array of embedding (512-d) or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # DeepFace can accept path or numpy array\n",
    "        if isinstance(img_path_or_array, (str, Path)):\n",
    "            img_input = str(img_path_or_array)\n",
    "        else:\n",
    "            # Convert BGR to RGB for DeepFace\n",
    "            img_input = cv2.cvtColor(img_path_or_array, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Generate embedding\n",
    "        embedding_obj = DeepFace.represent(\n",
    "            img_path=img_input,\n",
    "            model_name=FACE_MODEL,\n",
    "            enforce_detection=False,  # Don't fail if face not detected\n",
    "            detector_backend='opencv'\n",
    "        )\n",
    "        \n",
    "        # Extract embedding array\n",
    "        if isinstance(embedding_obj, list) and len(embedding_obj) > 0:\n",
    "            embedding = np.array(embedding_obj[0]['embedding'])\n",
    "        else:\n",
    "            embedding = np.array(embedding_obj['embedding'])\n",
    "        \n",
    "        print(f\"‚úÖ Embedding generated: shape {embedding.shape}\")\n",
    "        return embedding\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to generate embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def match_embedding(query_embedding, db_embeddings, db_df):\n",
    "    \"\"\"\n",
    "    Match query embedding against database\n",
    "    Args:\n",
    "        query_embedding: numpy array (512-d)\n",
    "        db_embeddings: list of numpy arrays\n",
    "        db_df: pandas DataFrame with student records\n",
    "    Returns:\n",
    "        (best_match_index, similarity_score) or (None, 0)\n",
    "    \"\"\"\n",
    "    if query_embedding is None or len(db_embeddings) == 0:\n",
    "        return None, 0\n",
    "    \n",
    "    # Reshape for sklearn\n",
    "    query_emb = query_embedding.reshape(1, -1)\n",
    "    \n",
    "    best_score = 0\n",
    "    best_idx = None\n",
    "    \n",
    "    for idx, db_emb in enumerate(db_embeddings):\n",
    "        if db_emb is None:\n",
    "            continue\n",
    "        \n",
    "        db_emb_reshaped = db_emb.reshape(1, -1)\n",
    "        \n",
    "        # Calculate cosine similarity\n",
    "        similarity = cosine_similarity(query_emb, db_emb_reshaped)[0][0]\n",
    "        \n",
    "        if similarity > best_score:\n",
    "            best_score = similarity\n",
    "            best_idx = idx\n",
    "    \n",
    "    print(f\"\\nüîç Best match: similarity = {best_score:.4f}\")\n",
    "    \n",
    "    if best_score >= SIMILARITY_THRESHOLD:\n",
    "        print(f\"‚úÖ MATCH FOUND! (threshold: {SIMILARITY_THRESHOLD})\")\n",
    "        return best_idx, best_score\n",
    "    else:\n",
    "        print(f\"‚ùå No match (below threshold {SIMILARITY_THRESHOLD})\")\n",
    "        return None, best_score\n",
    "\n",
    "\n",
    "print(\"‚úÖ Face verification functions loaded!\")\n",
    "print(\"Functions:\")\n",
    "print(\"  - capture_id_card() ‚Üí captures from webcam\")\n",
    "print(\"  - extract_photo(img) ‚Üí crops student photo\")\n",
    "print(\"  - get_embedding(img) ‚Üí generates 512-d embedding\")\n",
    "print(\"  - match_embedding(query, db, df) ‚Üí finds best match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639a134b",
   "metadata": {},
   "source": [
    "## Database Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eb81cb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Database functions loaded!\n",
      "Functions:\n",
      "  - load_database(path) ‚Üí loads CSV and embeddings\n",
      "  - add_to_database(path, id, name, dept, emb) ‚Üí adds/updates record\n"
     ]
    }
   ],
   "source": [
    "def load_database(db_path):\n",
    "    \"\"\"\n",
    "    Load student database from CSV\n",
    "    Columns: moodle_id, name, department, embedding (JSON string)\n",
    "    Returns: DataFrame, list of embeddings\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìÇ Loading database: {db_path}\")\n",
    "    \n",
    "    if not db_path.exists():\n",
    "        print(f\"‚ùå Database not found: {db_path}\")\n",
    "        print(\"   Creating sample database...\")\n",
    "        \n",
    "        # Create sample database\n",
    "        sample_data = {\n",
    "            'moodle_id': ['20210001', '20210002', '20210003'],\n",
    "            'name': ['John Doe', 'Jane Smith', 'Bob Johnson'],\n",
    "            'department': ['Computer Engineering', 'Information Technology', 'Computer Engineering'],\n",
    "            'embedding': ['[]', '[]', '[]']  # Empty embeddings\n",
    "        }\n",
    "        df = pd.DataFrame(sample_data)\n",
    "        df.to_csv(db_path, index=False)\n",
    "        print(f\"‚úÖ Sample database created: {db_path}\")\n",
    "        return df, []\n",
    "    \n",
    "    # Load CSV\n",
    "    df = pd.read_csv(db_path)\n",
    "    print(f\"‚úÖ Loaded {len(df)} records\")\n",
    "    \n",
    "    # Parse embeddings\n",
    "    embeddings = []\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            emb_str = row['embedding']\n",
    "            if pd.isna(emb_str) or emb_str == '[]' or emb_str == '':\n",
    "                embeddings.append(None)\n",
    "            else:\n",
    "                emb_array = np.array(json.loads(emb_str))\n",
    "                embeddings.append(emb_array)\n",
    "        except Exception as e:\n",
    "            print(f\"   Warning: Failed to parse embedding for row {idx}: {e}\")\n",
    "            embeddings.append(None)\n",
    "    \n",
    "    valid_count = sum(1 for e in embeddings if e is not None)\n",
    "    print(f\"   Valid embeddings: {valid_count}/{len(embeddings)}\")\n",
    "    \n",
    "    return df, embeddings\n",
    "\n",
    "\n",
    "def add_to_database(db_path, moodle_id, name, department, embedding):\n",
    "    \"\"\"\n",
    "    Add or update student record in database\n",
    "    Args:\n",
    "        db_path: Path to CSV file\n",
    "        moodle_id: Student ID\n",
    "        name: Student name\n",
    "        department: Department name\n",
    "        embedding: numpy array (512-d)\n",
    "    \"\"\"\n",
    "    # Load existing database\n",
    "    if db_path.exists():\n",
    "        df = pd.read_csv(db_path)\n",
    "    else:\n",
    "        df = pd.DataFrame(columns=['moodle_id', 'name', 'department', 'embedding'])\n",
    "    \n",
    "    # Convert embedding to JSON string\n",
    "    emb_str = json.dumps(embedding.tolist()) if embedding is not None else '[]'\n",
    "    \n",
    "    # Check if student already exists\n",
    "    existing = df[df['moodle_id'] == moodle_id]\n",
    "    \n",
    "    if len(existing) > 0:\n",
    "        # Update existing record\n",
    "        df.loc[df['moodle_id'] == moodle_id, 'name'] = name\n",
    "        df.loc[df['moodle_id'] == moodle_id, 'department'] = department\n",
    "        df.loc[df['moodle_id'] == moodle_id, 'embedding'] = emb_str\n",
    "        print(f\"‚úÖ Updated record for {moodle_id}\")\n",
    "    else:\n",
    "        # Add new record\n",
    "        new_row = pd.DataFrame([{\n",
    "            'moodle_id': moodle_id,\n",
    "            'name': name,\n",
    "            'department': department,\n",
    "            'embedding': emb_str\n",
    "        }])\n",
    "        df = pd.concat([df, new_row], ignore_index=True)\n",
    "        print(f\"‚úÖ Added new record for {moodle_id}\")\n",
    "    \n",
    "    # Save database\n",
    "    df.to_csv(db_path, index=False)\n",
    "    print(f\"   Database saved: {db_path}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Database functions loaded!\")\n",
    "print(\"Functions:\")\n",
    "print(\"  - load_database(path) ‚Üí loads CSV and embeddings\")\n",
    "print(\"  - add_to_database(path, id, name, dept, emb) ‚Üí adds/updates record\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da16ad",
   "metadata": {},
   "source": [
    "## üöÄ Complete Verification Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "da18b8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Complete verification pipeline ready!\n",
      "\n",
      "Run: verify_id_card_complete()\n",
      "\n",
      "This will:\n",
      "  1. Capture ID card from webcam\n",
      "  2. Extract & save student photo\n",
      "  3. Generate face embedding\n",
      "  4. Compare with sample face\n",
      "  5. Match against database\n",
      "  6. Display results & visualization\n"
     ]
    }
   ],
   "source": [
    "def verify_id_card_complete():\n",
    "    \"\"\"\n",
    "    Complete face verification pipeline:\n",
    "    1. Capture ID card from webcam\n",
    "    2. Extract student photo\n",
    "    3. Generate embedding\n",
    "    4. Match against database\n",
    "    5. Display results\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üîê COMPLETE ID CARD FACE VERIFICATION SYSTEM\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Capture ID card\n",
    "    print(\"\\n[1/6] Capturing ID card from webcam...\")\n",
    "    id_card_img = capture_id_card()\n",
    "    \n",
    "    if id_card_img is None:\n",
    "        print(\"‚ùå No image captured\")\n",
    "        return\n",
    "    \n",
    "    # Convert to grayscale for detection\n",
    "    gray = cv2.cvtColor(id_card_img, cv2.COLOR_BGR2GRAY)\n",
    "    print(\"‚úÖ Converted to grayscale for processing\")\n",
    "    \n",
    "    # Step 2: Extract student photo\n",
    "    print(\"\\n[2/6] Extracting student photo from ID card...\")\n",
    "    cropped_photo = extract_photo(id_card_img)\n",
    "    \n",
    "    if cropped_photo is None:\n",
    "        print(\"‚ùå Failed to extract photo\")\n",
    "        return\n",
    "    \n",
    "    # Display cropped photo\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cv2.cvtColor(cropped_photo, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Cropped ID Card Photo\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Step 3: Generate embedding for cropped photo\n",
    "    print(\"\\n[3/6] Generating face embedding for ID card photo...\")\n",
    "    id_embedding = get_embedding(cropped_photo)\n",
    "    \n",
    "    if id_embedding is None:\n",
    "        print(\"‚ùå Failed to generate embedding\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Load database\n",
    "    print(\"\\n[4/6] Loading student database...\")\n",
    "    db_df, db_embeddings = load_database(DB_FILE)\n",
    "    \n",
    "    # Step 5: Match with sample face (if exists)\n",
    "    if SAMPLE_FACE.exists():\n",
    "        print(\"\\n[5/6] Comparing with sample face...\")\n",
    "        sample_embedding = get_embedding(SAMPLE_FACE)\n",
    "        \n",
    "        if sample_embedding is not None:\n",
    "            sample_query = id_embedding.reshape(1, -1)\n",
    "            sample_db = sample_embedding.reshape(1, -1)\n",
    "            sample_similarity = cosine_similarity(sample_query, sample_db)[0][0]\n",
    "            \n",
    "            print(f\"   Similarity with sample: {sample_similarity:.4f}\")\n",
    "            \n",
    "            if sample_similarity >= SIMILARITY_THRESHOLD:\n",
    "                print(f\"   ‚úÖ MATCH with sample face!\")\n",
    "            else:\n",
    "                print(f\"   ‚ùå No match with sample (threshold: {SIMILARITY_THRESHOLD})\")\n",
    "    else:\n",
    "        print(\"\\n[5/6] Sample face not found, skipping...\")\n",
    "    \n",
    "    # Step 6: Match against database\n",
    "    print(\"\\n[6/6] Matching against database...\")\n",
    "    best_idx, best_score = match_embedding(id_embedding, db_embeddings, db_df)\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä VERIFICATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if best_idx is not None:\n",
    "        match_record = db_df.iloc[best_idx]\n",
    "        print(\"‚úÖ AUTHORIZED ID CARD\")\n",
    "        print(f\"\\n   Student Details:\")\n",
    "        print(f\"   Moodle ID:   {match_record['moodle_id']}\")\n",
    "        print(f\"   Name:        {match_record['name']}\")\n",
    "        print(f\"   Department:  {match_record['department']}\")\n",
    "        print(f\"   Similarity:  {best_score:.4f}\")\n",
    "    else:\n",
    "        print(\"‚ùå UNAUTHORIZED ID\")\n",
    "        print(f\"   No matching student found in database\")\n",
    "        print(f\"   Best similarity: {best_score:.4f} (threshold: {SIMILARITY_THRESHOLD})\")\n",
    "    \n",
    "    print(f\"\\n‚è±Ô∏è  Total time: {elapsed_time:.2f}s\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Visualize side-by-side comparison\n",
    "    if best_idx is not None and SAMPLE_FACE.exists():\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        # ID card photo\n",
    "        axes[0].imshow(cv2.cvtColor(cropped_photo, cv2.COLOR_BGR2RGB))\n",
    "        axes[0].set_title(\"ID Card Photo (Cropped)\")\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Sample/matched photo\n",
    "        if SAMPLE_FACE.exists():\n",
    "            sample_img = cv2.imread(str(SAMPLE_FACE))\n",
    "            axes[1].imshow(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
    "            axes[1].set_title(f\"Database Match\\n{db_df.iloc[best_idx]['name']}\\nSimilarity: {best_score:.4f}\")\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, 'No sample image', ha='center', va='center')\n",
    "            axes[1].set_title(\"Database Match\")\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'authorized': best_idx is not None,\n",
    "        'match_index': best_idx,\n",
    "        'similarity': best_score,\n",
    "        'processing_time': elapsed_time\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"‚úÖ Complete verification pipeline ready!\")\n",
    "print(\"\\nRun: verify_id_card_complete()\")\n",
    "print(\"\\nThis will:\")\n",
    "print(\"  1. Capture ID card from webcam\")\n",
    "print(\"  2. Extract & save student photo\")\n",
    "print(\"  3. Generate face embedding\")\n",
    "print(\"  4. Compare with sample face\")\n",
    "print(\"  5. Match against database\")\n",
    "print(\"  6. Display results & visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e943fa5",
   "metadata": {},
   "source": [
    "## üéØ Quick Test - Run Verification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "725c75e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîê COMPLETE ID CARD FACE VERIFICATION SYSTEM\n",
      "======================================================================\n",
      "\n",
      "[1/6] Capturing ID card from webcam...\n",
      "\n",
      "======================================================================\n",
      "üì∑ CAPTURING ID CARD FROM WEBCAM\n",
      "======================================================================\n",
      "Instructions:\n",
      "  - Hold ID card flat and centered\n",
      "  - Press SPACE to capture\n",
      "  - Press Q to cancel\n",
      "======================================================================\n",
      "‚ùå Capture cancelled\n",
      "‚ùå Capture cancelled\n",
      "‚ùå No image captured\n",
      "‚ùå No image captured\n"
     ]
    }
   ],
   "source": [
    "# Run the complete face verification system!\n",
    "result = verify_id_card_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073265f",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Utility Functions - Add Students to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "09e7d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Utility functions loaded!\n",
      "\n",
      "Functions:\n",
      "  - register_new_student() ‚Üí capture & register interactively\n",
      "  - populate_database_from_images() ‚Üí bulk register from data/ folder\n"
     ]
    }
   ],
   "source": [
    "def register_new_student():\n",
    "    \"\"\"\n",
    "    Register a new student in the database by capturing their ID card\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üìù REGISTER NEW STUDENT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Capture ID card\n",
    "    print(\"\\n[1/4] Capturing ID card...\")\n",
    "    id_card_img = capture_id_card()\n",
    "    \n",
    "    if id_card_img is None:\n",
    "        print(\"‚ùå Registration cancelled\")\n",
    "        return\n",
    "    \n",
    "    # Extract photo\n",
    "    print(\"\\n[2/4] Extracting student photo...\")\n",
    "    cropped_photo = extract_photo(id_card_img)\n",
    "    \n",
    "    if cropped_photo is None:\n",
    "        print(\"‚ùå Failed to extract photo\")\n",
    "        return\n",
    "    \n",
    "    # Generate embedding\n",
    "    print(\"\\n[3/4] Generating face embedding...\")\n",
    "    embedding = get_embedding(cropped_photo)\n",
    "    \n",
    "    if embedding is None:\n",
    "        print(\"‚ùå Failed to generate embedding\")\n",
    "        return\n",
    "    \n",
    "    # Get student details (manual input for now)\n",
    "    print(\"\\n[4/4] Enter student details:\")\n",
    "    moodle_id = input(\"  Moodle ID (8 digits starting with 2): \").strip()\n",
    "    name = input(\"  Name: \").strip()\n",
    "    department = input(\"  Department: \").strip()\n",
    "    \n",
    "    if not moodle_id or not name or not department:\n",
    "        print(\"‚ùå Invalid details provided\")\n",
    "        return\n",
    "    \n",
    "    # Add to database\n",
    "    add_to_database(DB_FILE, moodle_id, name, department, embedding)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ STUDENT REGISTERED SUCCESSFULLY!\")\n",
    "    print(f\"   Moodle ID:  {moodle_id}\")\n",
    "    print(f\"   Name:       {name}\")\n",
    "    print(f\"   Department: {department}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "def populate_database_from_images():\n",
    "    \"\"\"\n",
    "    Populate database by processing ID card images from data folder\n",
    "    Useful for bulk registration\n",
    "    \"\"\"\n",
    "    print(\"=\"*70)\n",
    "    print(\"üì¶ BULK DATABASE POPULATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Get all images\n",
    "    image_files = list(DATA_DIR.glob(\"*.jpg\"))\n",
    "    print(f\"\\nFound {len(image_files)} images in {DATA_DIR}\")\n",
    "    \n",
    "    if len(image_files) == 0:\n",
    "        print(\"‚ùå No images found\")\n",
    "        return\n",
    "    \n",
    "    # Process first 5 images as example\n",
    "    sample_images = image_files[:5]\n",
    "    print(f\"\\nProcessing first {len(sample_images)} images as sample...\")\n",
    "    \n",
    "    for i, img_path in enumerate(sample_images, 1):\n",
    "        print(f\"\\n[{i}/{len(sample_images)}] Processing {img_path.name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Load image\n",
    "            img = cv2.imread(str(img_path))\n",
    "            \n",
    "            if img is None:\n",
    "                print(f\"   ‚ùå Failed to load image\")\n",
    "                continue\n",
    "            \n",
    "            # Try to detect ID card first\n",
    "            bbox = detect_id_card_trained(img, card_stats)\n",
    "            \n",
    "            if bbox:\n",
    "                x, y, w, h = bbox\n",
    "                card_img = img[y:y+h, x:x+w]\n",
    "            else:\n",
    "                # Assume whole image is the card\n",
    "                card_img = img\n",
    "            \n",
    "            # Extract photo\n",
    "            cropped = extract_photo(card_img)\n",
    "            \n",
    "            if cropped is None:\n",
    "                print(f\"   ‚ùå Failed to extract photo\")\n",
    "                continue\n",
    "            \n",
    "            # Generate embedding\n",
    "            embedding = get_embedding(cropped)\n",
    "            \n",
    "            if embedding is None:\n",
    "                print(f\"   ‚ùå Failed to generate embedding\")\n",
    "                continue\n",
    "            \n",
    "            # Use filename as ID (dummy data)\n",
    "            file_stem = img_path.stem\n",
    "            dummy_id = f\"202100{i:02d}\"\n",
    "            dummy_name = file_stem.replace('_', ' ').title()\n",
    "            dummy_dept = \"Computer Engineering\"\n",
    "            \n",
    "            # Add to database\n",
    "            add_to_database(DB_FILE, dummy_id, dummy_name, dummy_dept, embedding)\n",
    "            print(f\"   ‚úÖ Added: {dummy_name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ BULK POPULATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "\n",
    "print(\"‚úÖ Utility functions loaded!\")\n",
    "print(\"\\nFunctions:\")\n",
    "print(\"  - register_new_student() ‚Üí capture & register interactively\")\n",
    "print(\"  - populate_database_from_images() ‚Üí bulk register from data/ folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
